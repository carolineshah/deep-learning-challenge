{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"../Resources/charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "application_df = application_df.drop([\"EIN\", \"NAME\"], axis=1)\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE            17\n",
       "AFFILIATION                  6\n",
       "CLASSIFICATION              71\n",
       "USE_CASE                     5\n",
       "ORGANIZATION                 4\n",
       "STATUS                       2\n",
       "INCOME_AMT                   9\n",
       "SPECIAL_CONSIDERATIONS       2\n",
       "ASK_AMT                   8747\n",
       "IS_SUCCESSFUL                2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of unique values in each column.\n",
    "application_df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "APPLICATION_TYPE\n",
       "T3     27037\n",
       "T4      1542\n",
       "T6      1216\n",
       "T5      1173\n",
       "T19     1065\n",
       "T8       737\n",
       "T7       725\n",
       "T10      528\n",
       "T9       156\n",
       "T13       66\n",
       "T12       27\n",
       "T2        16\n",
       "T14        3\n",
       "T25        3\n",
       "T29        2\n",
       "T15        2\n",
       "T17        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "app_counts = application_df.value_counts(\"APPLICATION_TYPE\")\n",
    "app_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of application types to be replaced\n",
    "# use the variable name `application_types_to_replace`\n",
    "application_types_to_replace = list(app_counts[app_counts < 200].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in application_types_to_replace:\n",
    "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
    "\n",
    "# Check to make sure binning was successful\n",
    "application_df['APPLICATION_TYPE'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "         ...  \n",
       "C2190        1\n",
       "C2380        1\n",
       "C2500        1\n",
       "C2561        1\n",
       "C8210        1\n",
       "Length: 71, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at CLASSIFICATION value counts for binning\n",
    "class_counts = application_df.value_counts(\"CLASSIFICATION\")\n",
    "class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLASSIFICATION\n",
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "C2800       95\n",
       "C7100       75\n",
       "C1300       58\n",
       "C1280       50\n",
       "C1230       36\n",
       "C1400       34\n",
       "C2300       32\n",
       "C7200       32\n",
       "C1240       30\n",
       "C8000       20\n",
       "C7120       18\n",
       "C1500       16\n",
       "C1800       15\n",
       "C6000       15\n",
       "C1250       14\n",
       "C8200       11\n",
       "C1278       10\n",
       "C1238       10\n",
       "C1235        9\n",
       "C1237        9\n",
       "C7210        7\n",
       "C1720        6\n",
       "C4100        6\n",
       "C2400        6\n",
       "C1600        5\n",
       "C1257        5\n",
       "C2710        3\n",
       "C1260        3\n",
       "C0           3\n",
       "C1267        2\n",
       "C1246        2\n",
       "C1256        2\n",
       "C3200        2\n",
       "C1234        2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
    "bigger_class_counts = class_counts[class_counts > 1]\n",
    "bigger_class_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "C7000      777\n",
       "Other      669\n",
       "C1700      287\n",
       "C4000      194\n",
       "C5000      116\n",
       "C1270      114\n",
       "C2700      104\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a cutoff value and create a list of classifications to be replaced\n",
    "# use the variable name `classifications_to_replace`\n",
    "classifications_to_replace = list(class_counts[class_counts < 100].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in classifications_to_replace:\n",
    "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "application_df['CLASSIFICATION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                       0   \n",
       "1       1   108590              1                       0   \n",
       "2       1     5000              0                       0   \n",
       "3       1     6692              1                       0   \n",
       "4       1   142590              1                       0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                     1                     0                    0   \n",
       "1                     0                     0                    1   \n",
       "2                     0                     0                    0   \n",
       "3                     0                     0                    1   \n",
       "4                     0                     0                    1   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                    0                    0                    0  ...   \n",
       "1                    0                    0                    0  ...   \n",
       "2                    0                    1                    0  ...   \n",
       "3                    0                    0                    0  ...   \n",
       "4                    0                    0                    0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                  0                       0                         0   \n",
       "1                  1                       0                         0   \n",
       "2                  0                       0                         0   \n",
       "3                  0                       1                         0   \n",
       "4                  0                       0                         1   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                   0                 0                       0   \n",
       "1                   0                 0                       0   \n",
       "2                   0                 0                       0   \n",
       "3                   0                 0                       0   \n",
       "4                   0                 0                       0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0                0                  0                         1   \n",
       "1                0                  0                         1   \n",
       "2                0                  0                         1   \n",
       "3                0                  0                         1   \n",
       "4                0                  0                         1   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                         0  \n",
       "1                         0  \n",
       "2                         0  \n",
       "3                         0  \n",
       "4                         0  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert categorical data to numeric with `pd.get_dummies`\n",
    "app_dummies_df = pd.get_dummies(application_df)\n",
    "app_dummies_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "y = app_dummies_df[\"IS_SUCCESSFUL\"].values\n",
    "X = app_dummies_df.drop(\"IS_SUCCESSFUL\", axis=1).values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "X_scaler = scaler.fit(X_train)\n",
    "\n",
    "# Scale the data\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 8)                 400       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 18        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 421\n",
      "Trainable params: 421\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 12:20:46.873711: I tensorflow/core/platform/cpu_feature_guard.cc:145] This TensorFlow binary is optimized with Intel(R) MKL-DNN to use the following CPU instructions in performance critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in non-MKL-DNN operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-06-01 12:20:46.884690: I tensorflow/core/common_runtime/process_util.cc:115] Creating new thread pool with default inter op setting: 8. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# changed number of nodes in layers\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 2\n",
    "\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.6144 - accuracy: 0.6832\n",
      "Epoch 2/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5706 - accuracy: 0.7241\n",
      "Epoch 3/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5620 - accuracy: 0.7278\n",
      "Epoch 4/100\n",
      "25724/25724 [==============================] - 1s 40us/sample - loss: 0.5585 - accuracy: 0.7282\n",
      "Epoch 5/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5565 - accuracy: 0.7282\n",
      "Epoch 6/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5552 - accuracy: 0.7284\n",
      "Epoch 7/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5543 - accuracy: 0.7294\n",
      "Epoch 8/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5534 - accuracy: 0.7300\n",
      "Epoch 9/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5526 - accuracy: 0.7302\n",
      "Epoch 10/100\n",
      "25724/25724 [==============================] - 1s 52us/sample - loss: 0.5517 - accuracy: 0.7302\n",
      "Epoch 11/100\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5512 - accuracy: 0.7304\n",
      "Epoch 12/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5507 - accuracy: 0.7300\n",
      "Epoch 13/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5505 - accuracy: 0.7310\n",
      "Epoch 14/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5497 - accuracy: 0.7309\n",
      "Epoch 15/100\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5495 - accuracy: 0.7304\n",
      "Epoch 16/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5494 - accuracy: 0.7308\n",
      "Epoch 17/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5488 - accuracy: 0.7308\n",
      "Epoch 18/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5485 - accuracy: 0.7315\n",
      "Epoch 19/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5488 - accuracy: 0.7309\n",
      "Epoch 20/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5483 - accuracy: 0.7312\n",
      "Epoch 21/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5480 - accuracy: 0.7311\n",
      "Epoch 22/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5477 - accuracy: 0.7310\n",
      "Epoch 23/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5477 - accuracy: 0.7306\n",
      "Epoch 24/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5471 - accuracy: 0.7311\n",
      "Epoch 25/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5473 - accuracy: 0.7296\n",
      "Epoch 26/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5471 - accuracy: 0.7318\n",
      "Epoch 27/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5469 - accuracy: 0.7317\n",
      "Epoch 28/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5468 - accuracy: 0.7309\n",
      "Epoch 29/100\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5466 - accuracy: 0.7318\n",
      "Epoch 30/100\n",
      "25724/25724 [==============================] - 2s 61us/sample - loss: 0.5467 - accuracy: 0.7309\n",
      "Epoch 31/100\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5465 - accuracy: 0.7321\n",
      "Epoch 32/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5465 - accuracy: 0.7314\n",
      "Epoch 33/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5463 - accuracy: 0.7312\n",
      "Epoch 34/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5464 - accuracy: 0.7319\n",
      "Epoch 35/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5461 - accuracy: 0.7310\n",
      "Epoch 36/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5464 - accuracy: 0.7313\n",
      "Epoch 37/100\n",
      "25724/25724 [==============================] - 1s 48us/sample - loss: 0.5464 - accuracy: 0.7312\n",
      "Epoch 38/100\n",
      "25724/25724 [==============================] - 1s 51us/sample - loss: 0.5460 - accuracy: 0.7309\n",
      "Epoch 39/100\n",
      "25724/25724 [==============================] - 1s 57us/sample - loss: 0.5458 - accuracy: 0.7315\n",
      "Epoch 40/100\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5460 - accuracy: 0.7310\n",
      "Epoch 41/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5461 - accuracy: 0.7311\n",
      "Epoch 42/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5457 - accuracy: 0.7316\n",
      "Epoch 43/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5454 - accuracy: 0.7319\n",
      "Epoch 44/100\n",
      "25724/25724 [==============================] - 1s 41us/sample - loss: 0.5454 - accuracy: 0.7312\n",
      "Epoch 45/100\n",
      "25724/25724 [==============================] - 1s 43us/sample - loss: 0.5454 - accuracy: 0.7319\n",
      "Epoch 46/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5457 - accuracy: 0.7323\n",
      "Epoch 47/100\n",
      "25724/25724 [==============================] - 1s 42us/sample - loss: 0.5452 - accuracy: 0.7320\n",
      "Epoch 48/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5454 - accuracy: 0.7318\n",
      "Epoch 49/100\n",
      "25724/25724 [==============================] - 1s 47us/sample - loss: 0.5455 - accuracy: 0.7311\n",
      "Epoch 50/100\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5453 - accuracy: 0.7320\n",
      "Epoch 51/100\n",
      "25724/25724 [==============================] - 1s 44us/sample - loss: 0.5454 - accuracy: 0.7309\n",
      "Epoch 52/100\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5453 - accuracy: 0.7317\n",
      "Epoch 53/100\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 54/100\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5450 - accuracy: 0.7318\n",
      "Epoch 55/100\n",
      "25724/25724 [==============================] - 4s 143us/sample - loss: 0.5449 - accuracy: 0.7318\n",
      "Epoch 56/100\n",
      "25724/25724 [==============================] - 4s 170us/sample - loss: 0.5449 - accuracy: 0.7320\n",
      "Epoch 57/100\n",
      "25724/25724 [==============================] - 7s 263us/sample - loss: 0.5451 - accuracy: 0.7316\n",
      "Epoch 58/100\n",
      "25724/25724 [==============================] - 3s 122us/sample - loss: 0.5448 - accuracy: 0.7320\n",
      "Epoch 59/100\n",
      "25724/25724 [==============================] - 2s 59us/sample - loss: 0.5447 - accuracy: 0.7325\n",
      "Epoch 60/100\n",
      "25724/25724 [==============================] - 1s 46us/sample - loss: 0.5447 - accuracy: 0.7319\n",
      "Epoch 61/100\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5448 - accuracy: 0.7324\n",
      "Epoch 62/100\n",
      "25724/25724 [==============================] - 1s 50us/sample - loss: 0.5448 - accuracy: 0.7320\n",
      "Epoch 63/100\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5447 - accuracy: 0.7317\n",
      "Epoch 64/100\n",
      "25724/25724 [==============================] - 4s 137us/sample - loss: 0.5445 - accuracy: 0.7319\n",
      "Epoch 65/100\n",
      "25724/25724 [==============================] - 5s 180us/sample - loss: 0.5444 - accuracy: 0.7318\n",
      "Epoch 66/100\n",
      "25724/25724 [==============================] - 4s 164us/sample - loss: 0.5443 - accuracy: 0.7314\n",
      "Epoch 67/100\n",
      "25724/25724 [==============================] - 3s 126us/sample - loss: 0.5442 - accuracy: 0.7312\n",
      "Epoch 68/100\n",
      "25724/25724 [==============================] - 5s 180us/sample - loss: 0.5440 - accuracy: 0.7329\n",
      "Epoch 69/100\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5442 - accuracy: 0.7318\n",
      "Epoch 70/100\n",
      "25724/25724 [==============================] - 4s 168us/sample - loss: 0.5437 - accuracy: 0.7320\n",
      "Epoch 71/100\n",
      "25724/25724 [==============================] - 5s 183us/sample - loss: 0.5437 - accuracy: 0.7321\n",
      "Epoch 72/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5438 - accuracy: 0.7322\n",
      "Epoch 73/100\n",
      "25724/25724 [==============================] - 5s 203us/sample - loss: 0.5436 - accuracy: 0.7320\n",
      "Epoch 74/100\n",
      "25724/25724 [==============================] - 4s 162us/sample - loss: 0.5436 - accuracy: 0.7322\n",
      "Epoch 75/100\n",
      "25724/25724 [==============================] - 4s 145us/sample - loss: 0.5433 - accuracy: 0.7320\n",
      "Epoch 76/100\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.5433 - accuracy: 0.7320\n",
      "Epoch 77/100\n",
      "25724/25724 [==============================] - 4s 168us/sample - loss: 0.5433 - accuracy: 0.7325\n",
      "Epoch 78/100\n",
      "25724/25724 [==============================] - 7s 289us/sample - loss: 0.5433 - accuracy: 0.7322\n",
      "Epoch 79/100\n",
      "25724/25724 [==============================] - 5s 188us/sample - loss: 0.5434 - accuracy: 0.7322\n",
      "Epoch 80/100\n",
      "25724/25724 [==============================] - 5s 175us/sample - loss: 0.5432 - accuracy: 0.7324\n",
      "Epoch 81/100\n",
      "25724/25724 [==============================] - 4s 174us/sample - loss: 0.5432 - accuracy: 0.7319\n",
      "Epoch 82/100\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5428 - accuracy: 0.7320\n",
      "Epoch 83/100\n",
      "25724/25724 [==============================] - 4s 157us/sample - loss: 0.5433 - accuracy: 0.7319\n",
      "Epoch 84/100\n",
      "25724/25724 [==============================] - 4s 147us/sample - loss: 0.5427 - accuracy: 0.7326\n",
      "Epoch 85/100\n",
      "25724/25724 [==============================] - 7s 285us/sample - loss: 0.5429 - accuracy: 0.7326\n",
      "Epoch 86/100\n",
      "25724/25724 [==============================] - 4s 150us/sample - loss: 0.5428 - accuracy: 0.7325\n",
      "Epoch 87/100\n",
      "25724/25724 [==============================] - 4s 172us/sample - loss: 0.5427 - accuracy: 0.7318\n",
      "Epoch 88/100\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5426 - accuracy: 0.7324\n",
      "Epoch 89/100\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5427 - accuracy: 0.7325\n",
      "Epoch 90/100\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5426 - accuracy: 0.7327\n",
      "Epoch 91/100\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5427 - accuracy: 0.7320\n",
      "Epoch 92/100\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5423 - accuracy: 0.7324\n",
      "Epoch 93/100\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5427 - accuracy: 0.7338\n",
      "Epoch 94/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5423 - accuracy: 0.7324\n",
      "Epoch 95/100\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5424 - accuracy: 0.7330\n",
      "Epoch 96/100\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5422 - accuracy: 0.7328\n",
      "Epoch 97/100\n",
      "25724/25724 [==============================] - 2s 91us/sample - loss: 0.5423 - accuracy: 0.7331\n",
      "Epoch 98/100\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5422 - accuracy: 0.7336\n",
      "Epoch 99/100\n",
      "25724/25724 [==============================] - 2s 86us/sample - loss: 0.5422 - accuracy: 0.7333\n",
      "Epoch 100/100\n",
      "25724/25724 [==============================] - 4s 138us/sample - loss: 0.5420 - accuracy: 0.7324\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.5410 - accuracy: 0.7294\n",
      "Loss: 0.5502956149112379, Accuracy: 0.7294460535049438\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 8)                 400       \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 6)                 54        \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4)                 28        \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 5         \n",
      "=================================================================\n",
      "Total params: 487\n",
      "Trainable params: 487\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# added layer and changed epochs\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  8\n",
    "hidden_nodes_layer2 = 6\n",
    "hidden_nodes_layer3 = 4\n",
    "\n",
    "\n",
    "nn1 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn1.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn1.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn1.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/75\n",
      "25724/25724 [==============================] - 8s 308us/sample - loss: 0.6445 - accuracy: 0.6004\n",
      "Epoch 2/75\n",
      "25724/25724 [==============================] - 4s 162us/sample - loss: 0.5859 - accuracy: 0.7232\n",
      "Epoch 3/75\n",
      "25724/25724 [==============================] - 5s 194us/sample - loss: 0.5700 - accuracy: 0.7280\n",
      "Epoch 4/75\n",
      "25724/25724 [==============================] - 6s 240us/sample - loss: 0.5647 - accuracy: 0.7289\n",
      "Epoch 5/75\n",
      "25724/25724 [==============================] - 3s 97us/sample - loss: 0.5625 - accuracy: 0.7302\n",
      "Epoch 6/75\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5609 - accuracy: 0.7310\n",
      "Epoch 7/75\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5599 - accuracy: 0.7312\n",
      "Epoch 8/75\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5584 - accuracy: 0.7321\n",
      "Epoch 9/75\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.5577 - accuracy: 0.7320\n",
      "Epoch 10/75\n",
      "25724/25724 [==============================] - 2s 96us/sample - loss: 0.5572 - accuracy: 0.7324\n",
      "Epoch 11/75\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5567 - accuracy: 0.7311\n",
      "Epoch 12/75\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5566 - accuracy: 0.7327\n",
      "Epoch 13/75\n",
      "25724/25724 [==============================] - 3s 127us/sample - loss: 0.5564 - accuracy: 0.7328\n",
      "Epoch 14/75\n",
      "25724/25724 [==============================] - 6s 225us/sample - loss: 0.5563 - accuracy: 0.7318\n",
      "Epoch 15/75\n",
      "25724/25724 [==============================] - 5s 175us/sample - loss: 0.5563 - accuracy: 0.7331\n",
      "Epoch 16/75\n",
      "25724/25724 [==============================] - 6s 215us/sample - loss: 0.5562 - accuracy: 0.7321\n",
      "Epoch 17/75\n",
      "25724/25724 [==============================] - 7s 256us/sample - loss: 0.5562 - accuracy: 0.7327\n",
      "Epoch 18/75\n",
      "25724/25724 [==============================] - 8s 319us/sample - loss: 0.5563 - accuracy: 0.7330\n",
      "Epoch 19/75\n",
      "25724/25724 [==============================] - 8s 321us/sample - loss: 0.5560 - accuracy: 0.7334\n",
      "Epoch 20/75\n",
      "25724/25724 [==============================] - 7s 280us/sample - loss: 0.5560 - accuracy: 0.7335\n",
      "Epoch 21/75\n",
      "25724/25724 [==============================] - 4s 156us/sample - loss: 0.5554 - accuracy: 0.7329\n",
      "Epoch 22/75\n",
      "25724/25724 [==============================] - 6s 246us/sample - loss: 0.5554 - accuracy: 0.7334\n",
      "Epoch 23/75\n",
      "25724/25724 [==============================] - 6s 240us/sample - loss: 0.5552 - accuracy: 0.7331\n",
      "Epoch 24/75\n",
      "25724/25724 [==============================] - 4s 155us/sample - loss: 0.5555 - accuracy: 0.7334\n",
      "Epoch 25/75\n",
      "25724/25724 [==============================] - 6s 231us/sample - loss: 0.5552 - accuracy: 0.7332\n",
      "Epoch 26/75\n",
      "25724/25724 [==============================] - 8s 295us/sample - loss: 0.5553 - accuracy: 0.7332\n",
      "Epoch 27/75\n",
      "25724/25724 [==============================] - 8s 306us/sample - loss: 0.5550 - accuracy: 0.7336\n",
      "Epoch 28/75\n",
      "25724/25724 [==============================] - 8s 312us/sample - loss: 0.5551 - accuracy: 0.7331\n",
      "Epoch 29/75\n",
      "25724/25724 [==============================] - 4s 159us/sample - loss: 0.5549 - accuracy: 0.7333\n",
      "Epoch 30/75\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.5546 - accuracy: 0.7331\n",
      "Epoch 31/75\n",
      "25724/25724 [==============================] - 7s 263us/sample - loss: 0.5546 - accuracy: 0.7326\n",
      "Epoch 32/75\n",
      "25724/25724 [==============================] - 7s 276us/sample - loss: 0.5545 - accuracy: 0.7334\n",
      "Epoch 33/75\n",
      "25724/25724 [==============================] - 4s 152us/sample - loss: 0.5548 - accuracy: 0.7334\n",
      "Epoch 34/75\n",
      "25724/25724 [==============================] - 6s 229us/sample - loss: 0.5546 - accuracy: 0.7333\n",
      "Epoch 35/75\n",
      "25724/25724 [==============================] - 6s 241us/sample - loss: 0.5546 - accuracy: 0.7333\n",
      "Epoch 36/75\n",
      "25724/25724 [==============================] - 7s 273us/sample - loss: 0.5545 - accuracy: 0.7338\n",
      "Epoch 37/75\n",
      "25724/25724 [==============================] - 7s 255us/sample - loss: 0.5543 - accuracy: 0.7339\n",
      "Epoch 38/75\n",
      "25724/25724 [==============================] - 3s 112us/sample - loss: 0.5544 - accuracy: 0.7332\n",
      "Epoch 39/75\n",
      "25724/25724 [==============================] - 2s 75us/sample - loss: 0.5543 - accuracy: 0.7331\n",
      "Epoch 40/75\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5544 - accuracy: 0.7325\n",
      "Epoch 41/75\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5545 - accuracy: 0.7346\n",
      "Epoch 42/75\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5543 - accuracy: 0.7338\n",
      "Epoch 43/75\n",
      "25724/25724 [==============================] - 2s 85us/sample - loss: 0.5540 - accuracy: 0.7340\n",
      "Epoch 44/75\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5537 - accuracy: 0.7339\n",
      "Epoch 45/75\n",
      "25724/25724 [==============================] - 2s 84us/sample - loss: 0.5540 - accuracy: 0.7328\n",
      "Epoch 46/75\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5540 - accuracy: 0.7344\n",
      "Epoch 47/75\n",
      "25724/25724 [==============================] - 2s 80us/sample - loss: 0.5539 - accuracy: 0.7334\n",
      "Epoch 48/75\n",
      "25724/25724 [==============================] - 2s 81us/sample - loss: 0.5539 - accuracy: 0.7344\n",
      "Epoch 49/75\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.5539 - accuracy: 0.7332\n",
      "Epoch 50/75\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5538 - accuracy: 0.7330\n",
      "Epoch 51/75\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5539 - accuracy: 0.7340\n",
      "Epoch 52/75\n",
      "25724/25724 [==============================] - 2s 95us/sample - loss: 0.5537 - accuracy: 0.7335\n",
      "Epoch 53/75\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.5540 - accuracy: 0.7326\n",
      "Epoch 54/75\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5536 - accuracy: 0.7329\n",
      "Epoch 55/75\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5538 - accuracy: 0.7344\n",
      "Epoch 56/75\n",
      "25724/25724 [==============================] - 3s 101us/sample - loss: 0.5536 - accuracy: 0.7333\n",
      "Epoch 57/75\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5536 - accuracy: 0.7345\n",
      "Epoch 58/75\n",
      "25724/25724 [==============================] - 2s 89us/sample - loss: 0.5538 - accuracy: 0.7330\n",
      "Epoch 59/75\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5537 - accuracy: 0.7339\n",
      "Epoch 60/75\n",
      "25724/25724 [==============================] - 2s 88us/sample - loss: 0.5535 - accuracy: 0.7338\n",
      "Epoch 61/75\n",
      "25724/25724 [==============================] - 3s 100us/sample - loss: 0.5536 - accuracy: 0.7335\n",
      "Epoch 62/75\n",
      "25724/25724 [==============================] - 2s 87us/sample - loss: 0.5538 - accuracy: 0.7333\n",
      "Epoch 63/75\n",
      "25724/25724 [==============================] - 2s 93us/sample - loss: 0.5537 - accuracy: 0.7337\n",
      "Epoch 64/75\n",
      "25724/25724 [==============================] - 2s 90us/sample - loss: 0.5536 - accuracy: 0.7349\n",
      "Epoch 65/75\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5535 - accuracy: 0.7338\n",
      "Epoch 66/75\n",
      "25724/25724 [==============================] - 2s 83us/sample - loss: 0.5534 - accuracy: 0.7328\n",
      "Epoch 67/75\n",
      "25724/25724 [==============================] - 2s 92us/sample - loss: 0.5534 - accuracy: 0.7336\n",
      "Epoch 68/75\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5536 - accuracy: 0.7330\n",
      "Epoch 69/75\n",
      "25724/25724 [==============================] - 2s 97us/sample - loss: 0.5535 - accuracy: 0.7327\n",
      "Epoch 70/75\n",
      "25724/25724 [==============================] - 3s 97us/sample - loss: 0.5535 - accuracy: 0.7335\n",
      "Epoch 71/75\n",
      "25724/25724 [==============================] - 3s 103us/sample - loss: 0.5533 - accuracy: 0.7339\n",
      "Epoch 72/75\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5534 - accuracy: 0.7339\n",
      "Epoch 73/75\n",
      "25724/25724 [==============================] - 2s 94us/sample - loss: 0.5535 - accuracy: 0.7334\n",
      "Epoch 74/75\n",
      "25724/25724 [==============================] - 3s 102us/sample - loss: 0.5530 - accuracy: 0.7346\n",
      "Epoch 75/75\n",
      "25724/25724 [==============================] - 3s 99us/sample - loss: 0.5535 - accuracy: 0.7331\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn1.fit(X_train_scaled,y_train,epochs=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 1s - loss: 0.5441 - accuracy: 0.7279\n",
      "Loss: 0.5598515594665928, Accuracy: 0.7279300093650818\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn1.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 14)                700       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 8)                 120       \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 829\n",
      "Trainable params: 829\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "# changing neurons and activation\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_nodes_layer1 =  14\n",
    "hidden_nodes_layer2 = 8\n",
    "\n",
    "\n",
    "nn2 = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn2.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"tanh\"))\n",
    "\n",
    "# Output layer\n",
    "nn2.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 25724 samples\n",
      "Epoch 1/50\n",
      "25724/25724 [==============================] - 5s 185us/sample - loss: 0.5986 - accuracy: 0.7002\n",
      "Epoch 2/50\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5600 - accuracy: 0.7244\n",
      "Epoch 3/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5540 - accuracy: 0.7285\n",
      "Epoch 4/50\n",
      "25724/25724 [==============================] - 1s 45us/sample - loss: 0.5519 - accuracy: 0.7292\n",
      "Epoch 5/50\n",
      "25724/25724 [==============================] - 2s 79us/sample - loss: 0.5503 - accuracy: 0.7296\n",
      "Epoch 6/50\n",
      "25724/25724 [==============================] - 4s 149us/sample - loss: 0.5494 - accuracy: 0.7305\n",
      "Epoch 7/50\n",
      "25724/25724 [==============================] - 4s 154us/sample - loss: 0.5486 - accuracy: 0.7315\n",
      "Epoch 8/50\n",
      "25724/25724 [==============================] - 4s 153us/sample - loss: 0.5472 - accuracy: 0.7316\n",
      "Epoch 9/50\n",
      "25724/25724 [==============================] - 6s 222us/sample - loss: 0.5475 - accuracy: 0.7316\n",
      "Epoch 10/50\n",
      "25724/25724 [==============================] - 7s 253us/sample - loss: 0.5469 - accuracy: 0.7318\n",
      "Epoch 11/50\n",
      "25724/25724 [==============================] - 8s 314us/sample - loss: 0.5461 - accuracy: 0.7308\n",
      "Epoch 12/50\n",
      "25724/25724 [==============================] - 10s 385us/sample - loss: 0.5460 - accuracy: 0.7327\n",
      "Epoch 13/50\n",
      "25724/25724 [==============================] - 9s 368us/sample - loss: 0.5455 - accuracy: 0.7311\n",
      "Epoch 14/50\n",
      "25724/25724 [==============================] - 1s 49us/sample - loss: 0.5451 - accuracy: 0.7318\n",
      "Epoch 15/50\n",
      "25724/25724 [==============================] - 3s 114us/sample - loss: 0.5449 - accuracy: 0.7317\n",
      "Epoch 16/50\n",
      "25724/25724 [==============================] - 2s 77us/sample - loss: 0.5446 - accuracy: 0.7322\n",
      "Epoch 17/50\n",
      "25724/25724 [==============================] - 2s 62us/sample - loss: 0.5442 - accuracy: 0.7313\n",
      "Epoch 18/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5439 - accuracy: 0.7326\n",
      "Epoch 19/50\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5437 - accuracy: 0.7322\n",
      "Epoch 20/50\n",
      "25724/25724 [==============================] - 2s 78us/sample - loss: 0.5435 - accuracy: 0.7317\n",
      "Epoch 21/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5431 - accuracy: 0.7326\n",
      "Epoch 22/50\n",
      "25724/25724 [==============================] - 2s 73us/sample - loss: 0.5428 - accuracy: 0.7332\n",
      "Epoch 23/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5428 - accuracy: 0.7343\n",
      "Epoch 24/50\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.5419 - accuracy: 0.7333\n",
      "Epoch 25/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5421 - accuracy: 0.7331\n",
      "Epoch 26/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5418 - accuracy: 0.7331\n",
      "Epoch 27/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5420 - accuracy: 0.7333\n",
      "Epoch 28/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5415 - accuracy: 0.7338\n",
      "Epoch 29/50\n",
      "25724/25724 [==============================] - 2s 63us/sample - loss: 0.5419 - accuracy: 0.7334\n",
      "Epoch 30/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5415 - accuracy: 0.7323\n",
      "Epoch 31/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5410 - accuracy: 0.7341\n",
      "Epoch 32/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5412 - accuracy: 0.7345\n",
      "Epoch 33/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5413 - accuracy: 0.7346\n",
      "Epoch 34/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5406 - accuracy: 0.7340\n",
      "Epoch 35/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5408 - accuracy: 0.7340\n",
      "Epoch 36/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5408 - accuracy: 0.7335\n",
      "Epoch 37/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5408 - accuracy: 0.7337\n",
      "Epoch 38/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5408 - accuracy: 0.7340\n",
      "Epoch 39/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5403 - accuracy: 0.7342\n",
      "Epoch 40/50\n",
      "25724/25724 [==============================] - 2s 68us/sample - loss: 0.5406 - accuracy: 0.7330\n",
      "Epoch 41/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5406 - accuracy: 0.7342\n",
      "Epoch 42/50\n",
      "25724/25724 [==============================] - 2s 66us/sample - loss: 0.5399 - accuracy: 0.7352\n",
      "Epoch 43/50\n",
      "25724/25724 [==============================] - 2s 69us/sample - loss: 0.5403 - accuracy: 0.7343\n",
      "Epoch 44/50\n",
      "25724/25724 [==============================] - 2s 64us/sample - loss: 0.5397 - accuracy: 0.7353\n",
      "Epoch 45/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5401 - accuracy: 0.7341\n",
      "Epoch 46/50\n",
      "25724/25724 [==============================] - 2s 70us/sample - loss: 0.5400 - accuracy: 0.7348\n",
      "Epoch 47/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5396 - accuracy: 0.7341\n",
      "Epoch 48/50\n",
      "25724/25724 [==============================] - 2s 60us/sample - loss: 0.5397 - accuracy: 0.7349\n",
      "Epoch 49/50\n",
      "25724/25724 [==============================] - 2s 67us/sample - loss: 0.5396 - accuracy: 0.7341\n",
      "Epoch 50/50\n",
      "25724/25724 [==============================] - 2s 65us/sample - loss: 0.5390 - accuracy: 0.7356\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn2.fit(X_train_scaled,y_train,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8575/1 - 0s - loss: 0.5467 - accuracy: 0.7291\n",
      "Loss: 0.5512710278235788, Accuracy: 0.7290962338447571\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn2.evaluate(X_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the accuracy\n",
    "history_df = pd.DataFrame(fit_model.history)\n",
    "history_df.plot(y=\"loss\")\n",
    "history_df.plot(y=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export our model to HDF5 file\n",
    "nn.save(\"../Resources/AlphabetSoupCharity_Optimization1.h5\")\n",
    "nn1.save(\"../Resources/AlphabetSoupCharity_Optimization2.h5\")\n",
    "nn2.save(\"../Resources/AlphabetSoupCharity_Optimization3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb602d11c3c2a208fbb9b735d9b456991c8fcc15c35abb06dc2e5818919f05c3"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
